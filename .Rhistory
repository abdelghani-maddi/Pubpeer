# Calculate the total number of "nb_aut" for each value of "annee_min"
df_nb_aut_total <- aggregate(publication ~ annee_min, data = df_nb_aut, n_distinct)
# Merge the two dataframes to calculate the proportion of each "Gtype" within each "annee_min" value
df_nb_aut_prop <- merge(df_nb_aut_agg, df_nb_aut_total, by = "annee_min", suffixes = c("_group", "_total"))
df_nb_aut_prop$prop <- df_nb_aut_prop$nb_aut_group / df_nb_aut_prop$nb_aut_total
View(df_nb_aut_prop)
df_nb_aut_prop$prop <- df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total
View(df_nb_aut_prop)
esquisse:::esquisser()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "%", y = "Years", fill = "M-F collaboration type") +
theme_minimal()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
df_nb_aut_prop$prop <- (df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total)*100
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
# Aggregate data by "annee_min" and "Gtype" columns and calculate the sum of "nb_aut" for each group
df_nb_aut_agg_dom <- aggregate(publication ~ annee_min + Gtype + Journal_Domaines_WOS, data = df_nb_aut, n_distinct)
# Calculate the total number of "nb_aut" for each value of "annee_min"
df_nb_aut_total_dom <- aggregate(publication ~ annee_min + Journal_Domaines_WOS, data = df_nb_aut, n_distinct)
# Merge the two dataframes to calculate the proportion of each "Gtype" within each "annee_min" value
df_nb_aut_prop_dom <- merge(df_nb_aut_agg, df_nb_aut_total, by = "annee_min", suffixes = c("_group", "_total"))
df_nb_aut_prop_dom$prop <- (df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total)*100
View(df_nb_aut_total_dom)
View(df_nb_aut_prop_dom)
View(df_nb_aut_agg_dom)
#  data
data_dom <- "SELECT * FROM public.data_frac_disc"
data_dom <- dbGetQuery(con,data_dom)
View(data_dom)
View(bdd_pub)
retract <- bdd_pub %>%
select(publication, Retracted)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) # matcher
esquisse:::esquisser()
df_retract %>%
filter(!(Journal_Domaines_WOS %in% c("[\"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Social Sciences\"]",
"[\"Arts & Humanities\", \"Technology\", \"Multidisciplinary\", \"Social Sciences\"]", "[\"Arts & Humanities\", \"Social Sciences\"]",
"[\"Social Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Social Sciences\", \"Technology\"]",
"[\"Arts & Humanities\", \"Technology\"]", "[\"Life Sciences & Biomedicine\", \"Physical Sciences\"]",
"[\"Arts & Humanities\"]", "[\"Physical Sciences\", \"Technology\", \"Life Sciences & Biomedicine\"]",
"[\"Physical Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Technology\"]",
"[\"Technology\", \"Life Sciences & Biomedicine\"]", "[\"Multidisciplinary\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]",
"[\"Physical Sciences\", \"Life Sciences & Biomedicine\", \"Technology\"]", "[\"Technology\", \"Physical Sciences\", \"Life Sciences & Biomedicine\"]",
"[\"Technology\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]", "[\"Social Sciences\", \"Arts & Humanities\"]",
"[\"Arts & Humanities\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]", "[\"Arts & Humanities\", \"Life Sciences & Biomedicine\"]",
"[\"Physical Sciences\", \"Arts & Humanities\"]", "[\"Technology\", \"Life Sciences & Biomedicine\", \"Physical Sciences\"]",
"[\"Life Sciences & Biomedicine\", \"Arts & Humanities\"]", "[\"Arts & Humanities\", \"Physical Sciences\"]",
"[\"Technology\", \"Social Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Multidisciplinary\", \"Life Sciences & Biomedicine\"]",
"[\"Arts & Humanities\", \"Physical Sciences\", \"Technology\"]", "[\"Life Sciences & Biomedicine\", \"Arts & Humanities\", \"Social Sciences\"]",
"[\"Life Sciences & Biomedicine\", \"Social Sciences\", \"Physical Sciences\"]")) | is.na(Journal_Domaines_WOS)) %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
df_retract %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE)
View(df_nb_aut)
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
View(df_retract)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retracted)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retracted$Retracted == TRUE)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retract)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retract$Retracted == TRUE)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retract$Retracted == "True")
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retract$Gtype[df_retract$Retracted == "True"])
# Calculate the relative proportion of each "Gtype" value for "Retracted" = TRUE
prop_retracted <- table_retracted / total_retracted
# Print the resulting table of relative proportions
prop_retracted
# Print the resulting table of relative proportions
plot(prop_retracted)
df_retracted <- bdd_pub %>%
select(publication, Retracted)
df_retracted <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retracted)
# Create a table of counts for each "Gtype" value
table_all <- table(df_retracted$Gtype)
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retracted$Gtype[df_retracted$Retracted == TRUE])
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retracted$Gtype[df_retracted$Retracted == "True"])
# Calculate the relative proportion of each "Gtype" value in the entire dataframe
prop_all <- table_all / total
# Calculate the relative proportion of each "Gtype" value for "Retracted" = TRUE
prop_retracted <- table_retracted / sum(df_retracted$Retracted == "True")
# Divide the relative proportions for "Retracted" = TRUE by those in the entire dataframe
relative_prop <- prop_retracted / prop_all
# Print the resulting table of relative proportions
relative_prop
esquisse:::esquisser()
# Divide the relative proportions for "Retracted" = TRUE by those in the entire dataframe
relative_prop <- as.data.frame(prop_retracted / prop_all)
View(relative_prop)
esquisse:::esquisser()
ggplot(relative_prop) +
aes(x = Var1, y = Freq) +
geom_col(fill = "#5B0B6E") +
labs(
x = "M-F collaboration type",
y = "Proportion in all Pubpeer / proportion in retracted publications"
) +
theme_minimal()
View(df_unnested)
library(readxl)
givenNames <- read_excel("~/Downloads/gender_proba.xlsx")
View(givenNames)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_final$gender[df_final$proba < 0.6] <- "unisex" # modifier les probas < 0.6 à Unisexe
df_final$gender[is.na(df_final$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_final %>%
tbl_summary(
include = c(publication, gender)
)
n_distinct(bdd_pub$publication)
describe(df_final$gender)
View(df_unnested)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
givenNames <- givenNames %>% # extraire valeurs uniques
unique()
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
# Supprimer les guillemets simples des noms d'auteurs
df_unnested$Auteur <- gsub("'", "", df_unnested$Auteur)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
View(df_unnested)
View(givenNames)
###
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "giben_name", all.x = TRUE) %>% # matcher
df_final %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "giben_name", all.x = TRUE) # matcher
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
View(df_stats_glob_m)
###
df_stats_glob <- df_unnested %>%
select(publication, tolower(prenoms))
###
df_unnested$prenoms <- tolower(df_unnested$prenoms)
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_final %>%
tbl_summary(
include = c(publication, gender)
)
View(df_stats_glob)
View(df_stats_glob_m)
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m$gender[df_final$proba < 0.6] <- "unisex" # modifier les probas < 0.6 à Unisexe
df_stats_glob_m$gender[is.na(df_final$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_stats_glob_m$gender[df_stats_glob_m$proba < 0.6] <- "unisex" # modifier les probas < 0.6 à Unisexe
df_stats_glob_m$gender[is.na(df_stats_glob_m$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender),
sort = list(everything() ~ "frequency")
)
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
# première représentation graphique
ggplot(nb_ann_com) +
aes(x = `df_nb_aut$annee_min`, fill = Gtype, weight = nb_pub) +
geom_bar() +
scale_fill_hue(direction = 1) +
labs(x = "Years", y = "# Commented publications", fill = "M-F collaboration type") +
theme_minimal()
# première représentation graphique
ggplot(nb_ann_com) +
aes(x = `df_nb_aut$annee_min`, fill = Gtype, weight = nb_pub) +
geom_bar() +
scale_fill_hue(direction = 1) +
labs(x = "Years", y = "# Commented publications", fill = "M-F collaboration type") +
theme_minimal()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
df_retract %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
ggplot(relative_prop) +
aes(x = Var1, y = Freq) +
geom_col(fill = "#5B0B6E") +
labs(
x = "M-F collaboration type",
y = "Proportion in all Pubpeer / proportion in retracted publications"
) +
theme_minimal()
i
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
rm(list = ls()) #supprimer tous les objets
library(stringr)
library(tibble)
library(tidytext)
library(textdata)
library(Hmisc)
library(zoo)
library(flextable)
library(DBI)
library(data.table)
library(tidyverse)
library(trimmer)
library(DescTools)
library(questionr)
library(RPostgres)
library(lubridate)
library(timechange)
library(urltools)
library(stringr)
library(rebus)
library(Matrix)
library(plyr)
library(sjmisc)
library(regexplain)
library(gtsummary)
library(igraph)
library(openxlsx2)
library(httr)
library(rvest)
library(XML)
# Connexion ----
con<-dbConnect(RPostgres::Postgres())
db <- 'SKEPTISCIENCE'  #provide the name of your db
host_db <- 'localhost' # server
db_port <- '5433'  # port DBA
db_user <- 'postgres' # nom utilisateur
db_password <- 'Maroua1912'
con <- dbConnect(RPostgres::Postgres(), dbname = db, host=host_db, port=db_port, user=db_user, password=db_password)
# Test connexion
dbListTables(con)
### Récupération des données ----
reqsql= paste('select inner_id, publication, "DateCreated" as date_com, html as comm from data_commentaires_2')
data_comm = dbGetQuery(con,reqsql)
# Transformer le format de la date du commentaire
data_comm$date_com <- as.Date.character(data_comm$date_com)
#### Etape 0 : Transformer le type de données pour plus de facilité/performance dans le traitement ----
URL_var <- as_tibble(data_comm) %>% # Etape 0
#### Etape 1 : Se limiter aux commentaires avec au moins un lien hypertexte  ----
subset(., comm %like% c("%http%","%www%","%WWW%","%HTTP%"))
# Fonction pour supprimer les balises HTML
remove_html_tags <- function(x) {
gsub("[>\\<]", " ", x) # .*? correspond à n'importe quel caractère répété 0 ou plusieurs fois, de manière non gourmande
}
# Application de la fonction à la colonne "comm"
URL_var$comm_sans_html <- sapply(URL_var$comm, remove_html_tags)
# Créer une nouvelle colonne pour stocker les URL extraites
URL_var$urls <- NA
# Parcourir chaque ligne et extraire l'URL
for (i in 1:nrow(URL_var)) {
# Extraire l'URL en utilisant une expression régulière
extracted_url <- str_extract_all(URL_var$comm_sans_html[i], "(?i)\\b(?:https?://|www\\.)\\S+(?:/|\\b)")
# Stocker l'URL extraite dans la nouvelle colonne
URL_var$urls[i] <- extracted_url
}
# séparer les URLs en autant de lignes
df_split <- unnest(URL_var, urls)
urls_parses <- url_parse(df_split$urls)
df <- merge(df_split, urls_parses, by = "row.names", all = F)
# faire un select distinct
urls_v1 <- data.frame(df$Row.names,df$publication,df$inner_id,df$date_com,df[,7:13])
names(urls_v1)[1:4] <- c("rowname","publication","inner_id","date_com")
urls_unique <- subset(urls_v1, !duplicated(paste(publication, inner_id, urls)))
# Utiliser la fonction ave() pour ajouter une colonne avec une ### séquence ### numérique qui se réinitialise selon id et suit l'ordre des rownames
urls_unique <- urls_unique[order(urls_unique$publication, as.numeric(urls_unique$rowname)),]
urls_unique$sequence <- ave(urls_unique$rowname, urls_unique$publication, FUN = function(x) seq_along(x))
View(urls_unique)
View(df)
View(urls_unique)
f <- factor(urls_unique$domain) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
View(f)
# Typologie des sites : tableau de correspondance ----
class_sites <- readxl::read_xlsx("classification sites2.xlsx", sheet = "Feuil3", col_names = TRUE)
# Créer une nouvelle colonne "typo" basée sur le tableau de correspondance
urls_unique$typo <- NA  # Initialiser la colonne à NA
# Parcourir chaque élément du vecteur class_sites$pattern dans l'ordre d'apparition
for (i in seq_along(class_sites$pattern)) {
site <- class_sites$pattern[i]
type <- class_sites$type[i]
# Trouver les éléments de urls_unique$domain qui correspondent à site
matches <- grepl(site, urls_unique$domain)
# Ne mettre à jour la colonne typo que pour les éléments non encore typés et correspondant à site
urls_unique$typo[matches & is.na(urls_unique$typo)] <- type
}
# Supprimer les lignes contenant la chaîne "http" (liées à un problème de pasing)
urls_unique <- urls_unique %>% filter(!grepl("http", domain))
urls_unique <- urls_unique[grep("\\.", urls_unique$domain), ]
View(urls_unique)
## Recoding urls_unique$typo
urls_unique$typo <- factor(urls_unique$typo) %>%
fct_explicit_na("Autre")
View(urls_unique)
## Recoding urls_unique$typo
urls_unique$typo <- factor(urls_unique$typo) %>%
fct_na_value_to_level("Autre")
View(urls_unique)
# Calcul de la fréquence des sites "autre" pour avoir une idée plus précise
f <- factor(urls_unique$domain[urls_unique$typo=="Autre"]) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
View(freqsit)
# Calcul de la fréquence des sites "autre" pour avoir une idée plus précise
f2 <- factor(urls_unique$typo[urls_unique$typo!="pubpeer"]) |>
fct_infreq() |>
questionr::freq()
freqsit2 <- data.frame(rownames(f2),f2)
names(freqsit2) = c("site","nb","part","freq")
View(freqsit2)
# Calcul de la fréquence des sites pour avoir une idée plus précise
f <- factor(urls_unique$typo[urls_unique$typo != "pubpeer" & urls_unique$typo != "Editeur - revue"]) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
rm(list = ls()) #supprimer tous les objets
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
# Connexion ----
# donnees depuis local w
data_urls <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/donnees_urls_fin.xlsx")
con<-dbConnect(RPostgres::Postgres())
db <- 'SKEPTISCIENCE'  #provide the name of your db
host_db <- 'localhost' # server
db_port <- '5433'  # port DBA
db_user <- 'postgres' # nom utilisateur
db_password <- 'Maroua1912'
con <- dbConnect(RPostgres::Postgres(), dbname = db, host=host_db, port=db_port, user=db_user, password=db_password)
# Test connexion
dbListTables(con)
### Récupération des données ----
reqsql= paste('select inner_id, publication, "DateCreated" as date_com, html as comm from data_commentaires')
data_comm = dbGetQuery(con,reqsql)
## Recuperation de la date
data_urls <- merge(data_urls, data_comm, by = c("inner_id", "publication"), all.x = TRUE)
# Transformer le format de la date du commentaire
data_urls$annee <- format(data_urls$date_com.y, "%Y")
data_urls$annee <- format(data_urls$date_com, "%Y") # local
# Transformer le format de la date du commentaire
data_urls$annee <- format(data_urls$date_com.y, "%Y")
data_comm = dbGetQuery(con,reqsql)
# donnees depuis local w
data_urls <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/donnees_urls_fin.xlsx")
dfMed <- subset(data_urls, typo == 'Médias') %>%
unique()
# Calcul de la fréquence des sites pour avoir une idée plus précise
f <- factor(dfMed$domain) |>
fct_infreq() |>
questionr::freq()
freqmed <- data.frame(rownames(f),f)
names(freqmed) = c("site","nb","part","freq")
# Calcul de la distance Levenshtein et récupération du fichier
# pour le calcul le fichier "Levenshtein distance.R" est utilisé
# fichier de sortie : voir dossier bdd
grp_leven <- readxl::read_excel("D:/bdd/grp_levenshtein.xlsx")
grp_leven <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/grp_levenshtein 2.xlsx")
# Parcourir chaque élément de la colonne "pattern" du dataframe "grp_leven"
for (i in 1:nrow(grp_leven)) {
# Trouver les indices des éléments de la colonne "domain" qui contiennent la chaîne de caractères spécifiée dans "pattern"
idx <- grep(grp_leven$pattern[i], dfMed$domain)
# Remplacer les valeurs correspondantes dans la colonne "domain" par la valeur correspondante dans la colonne "remplacement"
dfMed$domain[idx] <- grp_leven$remplacement[i]
}
## Nombre d'apparitions par année
nb <- dfMed %>%
select(domain, annee)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
nb2 <- nb %>%
group_by(annee) %>%
mutate(total = sum(n)) %>%
group_by(domain) %>%
mutate(part = n/total*100) %>%
ungroup()
## Nombre d'apparitions par année
nb <- dfMed %>%
select(domain, annee)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
