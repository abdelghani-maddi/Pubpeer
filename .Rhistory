# Calculate the total number of "nb_aut" for each value of "annee_min"
df_nb_aut_total <- aggregate(publication ~ annee_min, data = df_nb_aut, n_distinct)
# Merge the two dataframes to calculate the proportion of each "Gtype" within each "annee_min" value
df_nb_aut_prop <- merge(df_nb_aut_agg, df_nb_aut_total, by = "annee_min", suffixes = c("_group", "_total"))
df_nb_aut_prop$prop <- df_nb_aut_prop$nb_aut_group / df_nb_aut_prop$nb_aut_total
View(df_nb_aut_prop)
df_nb_aut_prop$prop <- df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total
View(df_nb_aut_prop)
esquisse:::esquisser()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "%", y = "Years", fill = "M-F collaboration type") +
theme_minimal()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
df_nb_aut_prop$prop <- (df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total)*100
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
# Aggregate data by "annee_min" and "Gtype" columns and calculate the sum of "nb_aut" for each group
df_nb_aut_agg_dom <- aggregate(publication ~ annee_min + Gtype + Journal_Domaines_WOS, data = df_nb_aut, n_distinct)
# Calculate the total number of "nb_aut" for each value of "annee_min"
df_nb_aut_total_dom <- aggregate(publication ~ annee_min + Journal_Domaines_WOS, data = df_nb_aut, n_distinct)
# Merge the two dataframes to calculate the proportion of each "Gtype" within each "annee_min" value
df_nb_aut_prop_dom <- merge(df_nb_aut_agg, df_nb_aut_total, by = "annee_min", suffixes = c("_group", "_total"))
df_nb_aut_prop_dom$prop <- (df_nb_aut_prop$publication_group / df_nb_aut_prop$publication_total)*100
View(df_nb_aut_total_dom)
View(df_nb_aut_prop_dom)
View(df_nb_aut_agg_dom)
#  data
data_dom <- "SELECT * FROM public.data_frac_disc"
data_dom <- dbGetQuery(con,data_dom)
View(data_dom)
View(bdd_pub)
retract <- bdd_pub %>%
select(publication, Retracted)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) # matcher
esquisse:::esquisser()
df_retract %>%
filter(!(Journal_Domaines_WOS %in% c("[\"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Social Sciences\"]",
"[\"Arts & Humanities\", \"Technology\", \"Multidisciplinary\", \"Social Sciences\"]", "[\"Arts & Humanities\", \"Social Sciences\"]",
"[\"Social Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Social Sciences\", \"Technology\"]",
"[\"Arts & Humanities\", \"Technology\"]", "[\"Life Sciences & Biomedicine\", \"Physical Sciences\"]",
"[\"Arts & Humanities\"]", "[\"Physical Sciences\", \"Technology\", \"Life Sciences & Biomedicine\"]",
"[\"Physical Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Life Sciences & Biomedicine\", \"Technology\"]",
"[\"Technology\", \"Life Sciences & Biomedicine\"]", "[\"Multidisciplinary\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]",
"[\"Physical Sciences\", \"Life Sciences & Biomedicine\", \"Technology\"]", "[\"Technology\", \"Physical Sciences\", \"Life Sciences & Biomedicine\"]",
"[\"Technology\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]", "[\"Social Sciences\", \"Arts & Humanities\"]",
"[\"Arts & Humanities\", \"Life Sciences & Biomedicine\", \"Social Sciences\"]", "[\"Arts & Humanities\", \"Life Sciences & Biomedicine\"]",
"[\"Physical Sciences\", \"Arts & Humanities\"]", "[\"Technology\", \"Life Sciences & Biomedicine\", \"Physical Sciences\"]",
"[\"Life Sciences & Biomedicine\", \"Arts & Humanities\"]", "[\"Arts & Humanities\", \"Physical Sciences\"]",
"[\"Technology\", \"Social Sciences\", \"Life Sciences & Biomedicine\"]", "[\"Multidisciplinary\", \"Life Sciences & Biomedicine\"]",
"[\"Arts & Humanities\", \"Physical Sciences\", \"Technology\"]", "[\"Life Sciences & Biomedicine\", \"Arts & Humanities\", \"Social Sciences\"]",
"[\"Life Sciences & Biomedicine\", \"Social Sciences\", \"Physical Sciences\"]")) | is.na(Journal_Domaines_WOS)) %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
df_retract %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE)
View(df_nb_aut)
View(df_retract)
df_retract <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
View(df_retract)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retracted)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retracted$Retracted == TRUE)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retract)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retract$Retracted == TRUE)
# Calculate the total number of rows where "Retracted" is "True"
total_retracted <- sum(df_retract$Retracted == "True")
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retract$Gtype[df_retract$Retracted == "True"])
# Calculate the relative proportion of each "Gtype" value for "Retracted" = TRUE
prop_retracted <- table_retracted / total_retracted
# Print the resulting table of relative proportions
prop_retracted
# Print the resulting table of relative proportions
plot(prop_retracted)
df_retracted <- bdd_pub %>%
select(publication, Retracted)
df_retracted <- merge(df_nb_aut, retract, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(publication, Gtype, Retracted)
# Calculate the total number of rows in the dataframe
total <- nrow(df_retracted)
# Create a table of counts for each "Gtype" value
table_all <- table(df_retracted$Gtype)
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retracted$Gtype[df_retracted$Retracted == TRUE])
# Create a table of counts for each "Gtype" value where "Retracted" is "True"
table_retracted <- table(df_retracted$Gtype[df_retracted$Retracted == "True"])
# Calculate the relative proportion of each "Gtype" value in the entire dataframe
prop_all <- table_all / total
# Calculate the relative proportion of each "Gtype" value for "Retracted" = TRUE
prop_retracted <- table_retracted / sum(df_retracted$Retracted == "True")
# Divide the relative proportions for "Retracted" = TRUE by those in the entire dataframe
relative_prop <- prop_retracted / prop_all
# Print the resulting table of relative proportions
relative_prop
esquisse:::esquisser()
# Divide the relative proportions for "Retracted" = TRUE by those in the entire dataframe
relative_prop <- as.data.frame(prop_retracted / prop_all)
View(relative_prop)
esquisse:::esquisser()
ggplot(relative_prop) +
aes(x = Var1, y = Freq) +
geom_col(fill = "#5B0B6E") +
labs(
x = "M-F collaboration type",
y = "Proportion in all Pubpeer / proportion in retracted publications"
) +
theme_minimal()
View(df_unnested)
library(readxl)
givenNames <- read_excel("~/Downloads/gender_proba.xlsx")
View(givenNames)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_final$gender[df_final$proba < 0.6] <- "unisex" # modifier les probas < 0.6 Ã  Unisexe
df_final$gender[is.na(df_final$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_final %>%
tbl_summary(
include = c(publication, gender)
)
n_distinct(bdd_pub$publication)
describe(df_final$gender)
View(df_unnested)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
givenNames <- givenNames %>% # extraire valeurs uniques
unique()
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
# Supprimer les guillemets simples des noms d'auteurs
df_unnested$Auteur <- gsub("'", "", df_unnested$Auteur)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
describe(df_final$gender)
View(df_unnested)
View(givenNames)
###
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "giben_name", all.x = TRUE) %>% # matcher
df_final %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "giben_name", all.x = TRUE) # matcher
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
View(df_stats_glob_m)
###
df_stats_glob <- df_unnested %>%
select(publication, tolower(prenoms))
###
df_unnested$prenoms <- tolower(df_unnested$prenoms)
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_final %>%
tbl_summary(
include = c(publication, gender)
)
View(df_stats_glob)
View(df_stats_glob_m)
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m$gender[df_final$proba < 0.6] <- "unisex" # modifier les probas < 0.6 Ã  Unisexe
df_stats_glob_m$gender[is.na(df_final$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob <- df_unnested %>%
select(publication, prenoms)
df_stats_glob_m <- merge(df_stats_glob, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE) # matcher
df_stats_glob_m$gender[df_stats_glob_m$proba < 0.6] <- "unisex" # modifier les probas < 0.6 Ã  Unisexe
df_stats_glob_m$gender[is.na(df_stats_glob_m$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender)
)
df_stats_glob_m %>%
tbl_summary(
include = c(publication, gender),
sort = list(everything() ~ "frequency")
)
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
# premiÃ¨re reprÃ©sentation graphique
ggplot(nb_ann_com) +
aes(x = `df_nb_aut$annee_min`, fill = Gtype, weight = nb_pub) +
geom_bar() +
scale_fill_hue(direction = 1) +
labs(x = "Years", y = "# Commented publications", fill = "M-F collaboration type") +
theme_minimal()
# premiÃ¨re reprÃ©sentation graphique
ggplot(nb_ann_com) +
aes(x = `df_nb_aut$annee_min`, fill = Gtype, weight = nb_pub) +
geom_bar() +
scale_fill_hue(direction = 1) +
labs(x = "Years", y = "# Commented publications", fill = "M-F collaboration type") +
theme_minimal()
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
df_retract %>%
filter(Retracted %in% "True") %>%
ggplot() +
aes(x = Gtype) +
geom_bar(fill = "#A20606") +
labs(x = "M-F collaboration type",
y = "# Retracted") +
theme_minimal()
ggplot(relative_prop) +
aes(x = Var1, y = Freq) +
geom_col(fill = "#5B0B6E") +
labs(
x = "M-F collaboration type",
y = "Proportion in all Pubpeer / proportion in retracted publications"
) +
theme_minimal()
i
# View the resulting dataframe
df_nb_aut_prop %>%
filter(!(annee_min %in% "2012")) %>%
ggplot() +
aes(x = annee_min, y = prop, fill = Gtype) +
geom_col() +
scale_fill_viridis_d(option = "viridis", direction = 1) +
labs(x = "Years", y = "%", fill = "M-F collaboration type") +
theme_minimal()
rm(list = ls()) #supprimer tous les objets
library(stringr)
library(tibble)
library(tidytext)
library(textdata)
library(Hmisc)
library(zoo)
library(flextable)
library(DBI)
library(data.table)
library(tidyverse)
library(trimmer)
library(DescTools)
library(questionr)
library(RPostgres)
library(lubridate)
library(timechange)
library(urltools)
library(stringr)
library(rebus)
library(Matrix)
library(plyr)
library(sjmisc)
library(regexplain)
library(gtsummary)
library(igraph)
library(openxlsx2)
library(httr)
library(rvest)
library(XML)
# Connexion ----
con<-dbConnect(RPostgres::Postgres())
db <- 'SKEPTISCIENCE'  #provide the name of your db
host_db <- 'localhost' # server
db_port <- '5433'  # port DBA
db_user <- 'postgres' # nom utilisateur
db_password <- 'Maroua1912'
con <- dbConnect(RPostgres::Postgres(), dbname = db, host=host_db, port=db_port, user=db_user, password=db_password)
# Test connexion
dbListTables(con)
### RÃ©cupÃ©ration des donnÃ©es ----
reqsql= paste('select inner_id, publication, "DateCreated" as date_com, html as comm from data_commentaires_2')
data_comm = dbGetQuery(con,reqsql)
# Transformer le format de la date du commentaire
data_comm$date_com <- as.Date.character(data_comm$date_com)
#### Etape 0 : Transformer le type de donnÃ©es pour plus de facilitÃ©/performance dans le traitement ----
URL_var <- as_tibble(data_comm) %>% # Etape 0
#### Etape 1 : Se limiter aux commentaires avec au moins un lien hypertexte  ----
subset(., comm %like% c("%http%","%www%","%WWW%","%HTTP%"))
# Fonction pour supprimer les balises HTML
remove_html_tags <- function(x) {
gsub("[>\\<]", " ", x) # .*? correspond Ã  n'importe quel caractÃ¨re rÃ©pÃ©tÃ© 0 ou plusieurs fois, de maniÃ¨re non gourmande
}
# Application de la fonction Ã  la colonne "comm"
URL_var$comm_sans_html <- sapply(URL_var$comm, remove_html_tags)
# CrÃ©er une nouvelle colonne pour stocker les URL extraites
URL_var$urls <- NA
# Parcourir chaque ligne et extraire l'URL
for (i in 1:nrow(URL_var)) {
# Extraire l'URL en utilisant une expression rÃ©guliÃ¨re
extracted_url <- str_extract_all(URL_var$comm_sans_html[i], "(?i)\\b(?:https?://|www\\.)\\S+(?:/|\\b)")
# Stocker l'URL extraite dans la nouvelle colonne
URL_var$urls[i] <- extracted_url
}
# sÃ©parer les URLs en autant de lignes
df_split <- unnest(URL_var, urls)
urls_parses <- url_parse(df_split$urls)
df <- merge(df_split, urls_parses, by = "row.names", all = F)
# faire un select distinct
urls_v1 <- data.frame(df$Row.names,df$publication,df$inner_id,df$date_com,df[,7:13])
names(urls_v1)[1:4] <- c("rowname","publication","inner_id","date_com")
urls_unique <- subset(urls_v1, !duplicated(paste(publication, inner_id, urls)))
# Utiliser la fonction ave() pour ajouter une colonne avec une ### sÃ©quence ### numÃ©rique qui se rÃ©initialise selon id et suit l'ordre des rownames
urls_unique <- urls_unique[order(urls_unique$publication, as.numeric(urls_unique$rowname)),]
urls_unique$sequence <- ave(urls_unique$rowname, urls_unique$publication, FUN = function(x) seq_along(x))
View(urls_unique)
View(df)
View(urls_unique)
f <- factor(urls_unique$domain) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
View(f)
# Typologie des sites : tableau de correspondance ----
class_sites <- readxl::read_xlsx("classification sites2.xlsx", sheet = "Feuil3", col_names = TRUE)
# CrÃ©er une nouvelle colonne "typo" basÃ©e sur le tableau de correspondance
urls_unique$typo <- NA  # Initialiser la colonne Ã  NA
# Parcourir chaque Ã©lÃ©ment du vecteur class_sites$pattern dans l'ordre d'apparition
for (i in seq_along(class_sites$pattern)) {
site <- class_sites$pattern[i]
type <- class_sites$type[i]
# Trouver les Ã©lÃ©ments de urls_unique$domain qui correspondent Ã  site
matches <- grepl(site, urls_unique$domain)
# Ne mettre Ã  jour la colonne typo que pour les Ã©lÃ©ments non encore typÃ©s et correspondant Ã  site
urls_unique$typo[matches & is.na(urls_unique$typo)] <- type
}
# Supprimer les lignes contenant la chaÃ®ne "http" (liÃ©es Ã  un problÃ¨me de pasing)
urls_unique <- urls_unique %>% filter(!grepl("http", domain))
urls_unique <- urls_unique[grep("\\.", urls_unique$domain), ]
View(urls_unique)
## Recoding urls_unique$typo
urls_unique$typo <- factor(urls_unique$typo) %>%
fct_explicit_na("Autre")
View(urls_unique)
## Recoding urls_unique$typo
urls_unique$typo <- factor(urls_unique$typo) %>%
fct_na_value_to_level("Autre")
View(urls_unique)
# Calcul de la frÃ©quence des sites "autre" pour avoir une idÃ©e plus prÃ©cise
f <- factor(urls_unique$domain[urls_unique$typo=="Autre"]) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
View(freqsit)
# Calcul de la frÃ©quence des sites "autre" pour avoir une idÃ©e plus prÃ©cise
f2 <- factor(urls_unique$typo[urls_unique$typo!="pubpeer"]) |>
fct_infreq() |>
questionr::freq()
freqsit2 <- data.frame(rownames(f2),f2)
names(freqsit2) = c("site","nb","part","freq")
View(freqsit2)
# Calcul de la frÃ©quence des sites pour avoir une idÃ©e plus prÃ©cise
f <- factor(urls_unique$typo[urls_unique$typo != "pubpeer" & urls_unique$typo != "Editeur - revue"]) |>
fct_infreq() |>
questionr::freq()
freqsit <- data.frame(rownames(f),f)
names(freqsit) = c("site","nb","part","freq")
rm(list = ls()) #supprimer tous les objets
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
# Connexion ----
# donnees depuis local w
data_urls <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/donnees_urls_fin.xlsx")
con<-dbConnect(RPostgres::Postgres())
db <- 'SKEPTISCIENCE'  #provide the name of your db
host_db <- 'localhost' # server
db_port <- '5433'  # port DBA
db_user <- 'postgres' # nom utilisateur
db_password <- 'Maroua1912'
con <- dbConnect(RPostgres::Postgres(), dbname = db, host=host_db, port=db_port, user=db_user, password=db_password)
# Test connexion
dbListTables(con)
### RÃ©cupÃ©ration des donnÃ©es ----
reqsql= paste('select inner_id, publication, "DateCreated" as date_com, html as comm from data_commentaires')
data_comm = dbGetQuery(con,reqsql)
## Recuperation de la date
data_urls <- merge(data_urls, data_comm, by = c("inner_id", "publication"), all.x = TRUE)
# Transformer le format de la date du commentaire
data_urls$annee <- format(data_urls$date_com.y, "%Y")
data_urls$annee <- format(data_urls$date_com, "%Y") # local
# Transformer le format de la date du commentaire
data_urls$annee <- format(data_urls$date_com.y, "%Y")
data_comm = dbGetQuery(con,reqsql)
# donnees depuis local w
data_urls <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/donnees_urls_fin.xlsx")
dfMed <- subset(data_urls, typo == 'MÃ©dias') %>%
unique()
# Calcul de la frÃ©quence des sites pour avoir une idÃ©e plus prÃ©cise
f <- factor(dfMed$domain) |>
fct_infreq() |>
questionr::freq()
freqmed <- data.frame(rownames(f),f)
names(freqmed) = c("site","nb","part","freq")
# Calcul de la distance Levenshtein et rÃ©cupÃ©ration du fichier
# pour le calcul le fichier "Levenshtein distance.R" est utilisÃ©
# fichier de sortie : voir dossier bdd
grp_leven <- readxl::read_excel("D:/bdd/grp_levenshtein.xlsx")
grp_leven <- readxl::read_excel("~/Documents/Pubpeer project/Pubpeer explo/grp_levenshtein 2.xlsx")
# Parcourir chaque Ã©lÃ©ment de la colonne "pattern" du dataframe "grp_leven"
for (i in 1:nrow(grp_leven)) {
# Trouver les indices des Ã©lÃ©ments de la colonne "domain" qui contiennent la chaÃ®ne de caractÃ¨res spÃ©cifiÃ©e dans "pattern"
idx <- grep(grp_leven$pattern[i], dfMed$domain)
# Remplacer les valeurs correspondantes dans la colonne "domain" par la valeur correspondante dans la colonne "remplacement"
dfMed$domain[idx] <- grp_leven$remplacement[i]
}
## Nombre d'apparitions par annÃ©e
nb <- dfMed %>%
select(domain, annee)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
nb2 <- nb %>%
group_by(annee) %>%
mutate(total = sum(n)) %>%
group_by(domain) %>%
mutate(part = n/total*100) %>%
ungroup()
## Nombre d'apparitions par annÃ©e
nb <- dfMed %>%
select(domain, annee)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
