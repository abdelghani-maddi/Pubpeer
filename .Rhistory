Auteurs = strsplit(Auteurs, ",\\s+"), # Séparer les noms des auteurs en utilisant la virgule suivie d'un espace comme séparateur
Pays_institution = str_replace_all(Pays_institution, "[\\[\\]']", ""),
Pays_institution = strsplit(Pays_institution, ",\\s+")
) %>%
unnest(cols = c(Auteurs, Pays_institution)) %>% # Transformer la colonne "Auteurs" en lignes
rename(Auteur = Auteurs, Pays = Pays_institution) # Renommer les colonnes
# Extraction des auteurs
df_unnested <- df %>%
mutate(Auteurs_extraits = str_extract_all(Auteurs, "'([A-Z][a-z]+\\s)+([A-Z][a-z]+)'")) %>%
unnest(Auteurs_extraits)
# Décomposition de la colonne "Pays_institution"
pays <- df %>%
mutate(Pays_institution = str_extract_all(Pays_institution, "'[A-Z]{2}'")) %>%
unnest(Pays_institution)
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("id_publication", "Auteur" = "auteurs"))
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("publication", "Auteur" = "auteurs"))
View(pays)
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("publication", "Auteur"))
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("publication", "Auteurs"))
View(df_pays)
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("publication"))
View(df_pays)
View(df)
View(pays)
View(df_unnested)
View(df)
# Extraction des auteurs
df_unnested <- df %>%
mutate(Auteurs_extraits = str_extract_all(Auteurs, "([A-Z][a-z]+\\s)+([A-Z][a-z]+)")) %>%
unnest(Auteurs_extraits)
View(df_unnested)
View(df_unnested)
# Extraction des auteurs
df_unnested <- df %>%
mutate(Auteurs_extraits = str_extract_all(Auteurs, "'(([A-Z][a-z]+\\s)+[A-Z][a-z]+(-[a-z]+)?)+(?=\'|$)")) %>%
unnest(Auteurs_extraits)
View(df_unnested)
df_unnested <- df %>%
mutate(Auteurs_extraits = str_extract_all(Auteurs, "'([\\p{L}\\s-]*)'")) %>%
unnest(Auteurs_extraits) %>%
select(-Auteurs)
View(df_unnested)
# Jointure avec la table des auteurs
df_pays <- df_unnested %>%
left_join(pays, by = c("publication"))
# Décomposition de la colonne "Pays_institution"
pays <- df %>%
mutate(Pays_institution = str_extract_all(Pays_institution, "'[A-Z]{2}'")) %>%
unnest(Pays_institution)
# Supprimer les guillemets simples des noms d'auteurs
df_unnested$Auteur <- gsub("'", "", df_unnested$Auteur)
# Extraire le prénom de chaque nom d'auteur
df_unnested$prenoms <- sapply(strsplit(df_unnested$Auteur, " "), function(x) x[1])
df_unnested <- df %>%
mutate(Pays_extraits = str_split(Pays_institution, ", ")) %>%
unnest(Pays_extraits) %>%
mutate(Pays_extraits = str_remove(Pays_extraits, "['|\"]"))
View(df_unnested)
df_pays <- df %>%
mutate(Pays_extraits = str_split(Pays_institution, ", ")) %>%
unnest(Pays_extraits) %>%
mutate(Pays_extraits = str_remove(Pays_extraits, "['|\"]"))
# Extraction des auteurs
df_unnested <- df %>%
mutate(Auteurs_extraits = str_extract_all(Auteurs, "'([\\p{L}\\s-]*)'")) %>%
unnest(Auteurs_extraits) %>%
select(-Auteurs)
df_pays <- df %>%
mutate(Pays_extraits = str_split(Pays_institution, ", ")) %>%
unnest(Pays_extraits) %>%
mutate(Pays_extraits = str_remove(Pays_extraits, "['|\"]"))
View(pays)
View(df_pays)
df$Pays_institution <- ifelse(authors$Pays_institution == "None", "UNK", authors$Pays_institution)
df$Pays_institution <- ifelse(df$Pays_institution == "None", "UNK", df$Pays_institution)
df_pays <- df %>%
mutate(Pays_extraits = str_split(Pays_institution, ", ")) %>%
unnest(Pays_extraits) %>%
mutate(Pays_extraits = str_remove(Pays_extraits, "['|\"]"))
names(df_unnested)[names(df_unnested) == "Pays_extraits"] <- "Pays"
View(df_pays)
# Enlever les espaces et caractères spéciaux
df_pays$Pays_extraits <- gsub("[^A-Z]+", "", df_pays$Pays_extraits)
View(df_pays)
describe(df$Pays_institution)
# Extraire le prénom de chaque nom d'auteur
df_unnested$prenoms <- sapply(strsplit(df_unnested$Auteur, " "), function(x) x[1])
View(df_unnested)
# Renommer la nouvelle colonne "Auteurs"
names(df_unnested)[names(df_unnested) == "Auteurs_extraits"] <- "Auteur"
# Supprimer les guillemets simples des noms d'auteurs
df_unnested$Auteur <- gsub("'", "", df_unnested$Auteur)
View(df_unnested)
# Extraire le prénom de chaque nom d'auteur
df_unnested$prenoms <- sapply(strsplit(df_unnested$Auteur, " "), function(x) x[1])
# Exemple de données avec une colonne "prenoms" contenant les prénoms
authors <- data.frame( publication = df_unnested$publication,
prenoms = df_unnested$prenoms)
# Prédire le genre avec assign_gender
authors <- assign_gender(data_df = authors, first_name_col = "prenoms")
describe(authors$gender)
df_genderized <- genderize_df(df_unnested, "Auteur")
library(genderizeR)
authors <- genderize(authors$prenoms)$gender
authors2 <- genderize(authors$prenoms)$gender
authors$genre <- genderize(authors$prenoms)$gender
# Exemple de données
authorsss <- data.frame(prenoms = c("John", "Mary", "Joseph", "Sarah"))
# Assignation du genre à chaque auteur
authorsss$genre <- genderize(authors$prenoms)$gender
library(genderizeR)
View(df_unnested)
givenNames = findGivenNames(df_unnested$Auteur, progress = FALSE)
View(givenNames)
givenNames = givenNames[count > 100]
givenNames = givenNames[count > 0.5]
givenNames = givenNames[count > 0.5]
givenNames = givenNames[count > 0]
givenNames = findGivenNames(df_unnested$Auteur, progress = FALSE)
givenNames = findGivenNames(df_unnested$Auteur, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(givenNames)
describe(givenNames$gender)
# Genderize the original character vector
genderize(df_unnested, genderDB = givenNames, progress = FALSE)
View(df_unnested)
write.xlsx(givenNames, "D:/bdd/gender_proba.xlsx")
library(data.table)
write.xlsx(givenNames, "D:/bdd/gender_proba.xlsx")
library(openxlsx)
write.xlsx(givenNames, "D:/bdd/gender_proba.xlsx")
# Genderize the original character vector
a <- genderize(df_unnested$prenoms, genderDB = givenNames, progress = FALSE)
View(givenNames)
df_unnested$Auteur
df_unnested$Auteur[1:10]
genderDB = findGivenNames(df_unnested$Auteur[1:10], progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(genderDB)
x <- df_unnested$Auteur[1:10]
x <- df_unnested$Auteur[1:10]
genderDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(genderDB)
x <- df_unnested$prenoms[1:10]
x
genderDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(genderDB)
x <- df_unnested$Auteur[1:10]
genderDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(genderDB)
genderize(x, genderDB = givenNamesDB, progress = FALSE)
givenNamesDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
genderize(x, genderDB = givenNamesDB, progress = FALSE)
x <- df_unnested$Auteur[1:10]
givenNamesDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
genderize(x, genderDB = givenNamesDB, progress = FALSE)
View(genderDB)
View(genderDB)
View(genderDB)
View(df)
View(df_unnested)
textPrepare(x)
givenNamesDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(genderDB)
textPrepare(x)
x <- c("ana", "leone", "ma", "pascual")
textPrepare(x)
givenNamesDB = findGivenNames(x, progress = FALSE, apikey = '0005346dd6d511911a5c214026f97992')
View(givenNamesDB)
?textPrepare
View(givenNames)
names(givenNames) <- c("id", "gender", "given_name", "proba", "country_id")
View(givenNames)
write.xlsx(givenNames, "D:/bdd/gender_proba.xlsx")
View(df_unnested)
# matcher
df_unnested$Auteur
# matcher
df_unnested$prenoms
# matcher
df_unnested$prenoms <- tolower(df_unnested$prenoms)
df_unnested$prenoms
givenNames <- givenNames %>%
unique()
View(givenNames)
View(givenNames)
df_final <- merge(df_unnested, givenNames, by.x = "prenom", by.y = "given_name", all.x = TRUE)
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE)
View(df_final)
describe(df_final$gender)
df$gender[df$gender == 0.5] <- "unisex"
givenNames <- givenNames %>%
unique()
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE)
df$gender[df$gender == 0.5] <- "unisex"
df_final$gender[df_final$gender == 0.5] <- "unisex"
describe(df_final$gender)
df_final$gender[df_final$gender == "0.5"] <- "unisex"
describe(df_final$gender)
df_final$gender[df_final$gender == "0.5"]
df_final$gender == "0.5"
# matcher
df_unnested$prenoms <- tolower(df_unnested$prenoms)
givenNames <- givenNames %>%
unique()
df_final <- merge(df_unnested, givenNames, by.x = "prenoms", by.y = "given_name", all.x = TRUE)
df_final$gender[df_final$proba == 0.5] <- "unisex"
describe(df_final$gender)
df_final$gender[df_final$proba < 0.6] <- "unisex"
describe(df_final$gender)
df$gender[is.na(df$gender)] <- "initials" # modifier les "NA" de gender en "initials"
df_final$gender[is.na(df_final$gender)] <- "initials" # modifier les "NA" de gender en "initials"
describe(df_final$gender)
tb <- df_final %>%
select(publication, gender, `Nombre de commentaires`, Année, starts_with("Journal"))
View(tb)
## Analyse des données ----
`%not_in%` <- purrr::negate(`%in%`)
tb <- df_final %>%
select(publication, gender, `Nombre de commentaires`, Année, starts_with("Journal")) %>%
subset(., gender %not_in% c("initials", "unisex"))
write.xlsx(givenNames, "D:/bdd/tb_finale.xlsx")
tb %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE))
tb2 %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE))
tbfin <- tb %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE))
View(tbfin)
tb %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE)) %>%
select(-gender) %>%
left_join(tb, by = "publication")
tb <- df_final %>%
select(publication, gender, `Nombre de commentaires`, Année, starts_with("Journal")) %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE)) %>%
select(-gender) %>%
left_join(tb, by = "publication")
tb <- df_final %>%
select(publication, gender, `Nombre de commentaires`, Année, starts_with("Journal")) %>%
group_by(publication) %>%
summarize(female_part = mean(gender == "female", na.rm = TRUE))
View(tb)
tb <- df_final %>%
select(publication, gender, `Nombre de commentaires`, Année, starts_with("Journal")) %>%
subset(., gender %not_in% c("initials", "unisex"))
# faire une jointure
tb_final <- merge(tb, tbfin, by.x = "publication", by.y = "publication", all.x = TRUE) # matcher
View(tb_final)
# faire une jointure
tb_final <- merge(tb, tbfin, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(-gender)
View(tb_final)
# faire une jointure
tb_final <- merge(tb, tbfin, by.x = "publication", by.y = "publication", all.x = TRUE) %>% # matcher
select(-gender) %>%
unique()
View(tb_final)
esquisse:::esquisser()
write.xlsx(tb_final, "D:/bdd/tb_finale.xlsx")
mean(tb_final$female_part)
questionr:::icut()
esquisse:::esquisser()
tb_ech <- tb_final[tb_final$`Nombre de commentaires`>1]
tb_ech <- subset(tb_final, tb_final$`Nombre de commentaires`>1)
esquisse:::esquisser()
tb_ech %>% tbl_summary(
include = c(`Nombre de commentaires`, female_part)
)
questionr:::icut()
summary(tb_final$female_part)
write.xlsx(nb3, "D:/bdd/nombres_par_annee_site.xlsx")
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
write.xlsx(nb3, "D:/bdd/nombres_par_annee_site.xlsx")
# Analyse des médias
rm(list = ls()) #supprimer tous les objets
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
library(tidyverse)
library(questionr)
library(RPostgres)
library(lubridate)
library(urltools)
library(TraMineR)
library(cluster)
library(seqhandbook)
library(ade4)
library(explor)
library(FactoMineR)
library(factoextra)
library(labelled)
library(openxlsx)
library(openxlsx2)
library(officer)
### donnees local : commentaires
data_comm <- readxl::read_excel("D:/bdd/data_comm.xlsx")
data_comm <- data_comm %>%
select(inner_id, publication, DateCreated, html)
names(data_comm) <- c("inner_id", "publication", "date_com", "comm")
### En local :
data_urls <- readxl::read_excel("D:/bdd/data_urls.xlsx")
## Recuperation de la date
data_urls <- merge(data_urls, data_comm, by = c("inner_id", "publication"), all.x = TRUE)
# Transformer le format de la date du commentaire
data_urls$annee <- format(data_urls$date_com.y, "%Y")
data_urls$annee <- format(data_urls$date_com, "%Y") # local
## Select variables d'intérêt
data_urls <- select(data_urls, c("comm.y", "date_com", "annee", "inner_id", "publication", "urls", "scheme", "domain", "port", "path", "parameter", "fragment", "sequence", "typo"))
names(data_urls)[1:2] <- c("comm", "date_comm")
var_label(data_urls) <- c("Commentaire", "Date du commentaire", "Année du commentaire", "Identifiant du commentaire", "Identifiant de la publication",
"Urls entiers", "Schéma", "Domaine", "Port", "Chemin", "Filtres appliqués", "Fragment", "Séquence", "Typologie")
# Chercher les lignes où "path" contient "image" et "domain" contient "pubpeer"
rows_to_modify <- which(grepl("(image|jpeg|png|jpg|imgur)", data_urls$path, ignore.case = TRUE) & grepl("pubpeer", data_urls$domain, ignore.case = TRUE))
# Modifier les valeurs de "typo" dans les lignes sélectionnées
data_urls$typo[rows_to_modify] <- gsub("pubpeer", "image", data_urls$typo[rows_to_modify])
write.xlsx(data_urls, "D:/bdd/donnees_URLS_fin.xlsx")
dfMed <- subset(data_urls, typo == 'Médias') %>%
unique()
# Calcul de la fréquence des sites pour avoir une idée plus précise
f <- factor(dfMed$domain) |>
fct_infreq() |>
questionr::freq()
freqmed <- data.frame(rownames(f),f)
names(freqmed) = c("site","nb","part","freq")
# Calcul de la distance Levenshtein et récupération du fichier
# pour le calcul le fichier "Levenshtein distance.R" est utilisé
# fichier de sortie : voir dossier bdd
grp_leven <- read_excel("D:/bdd/grp_levenshtein.xlsx")
# Calcul de la distance Levenshtein et récupération du fichier
# pour le calcul le fichier "Levenshtein distance.R" est utilisé
# fichier de sortie : voir dossier bdd
grp_leven <- readxl::read_excel("D:/bdd/grp_levenshtein.xlsx")
# Parcourir chaque élément de la colonne "pattern" du dataframe "grp_leven"
for (i in 1:nrow(grp_leven)) {
# Trouver les indices des éléments de la colonne "domain" qui contiennent la chaîne de caractères spécifiée dans "pattern"
idx <- grep(grp_leven$pattern[i], dfMed$domain)
# Remplacer les valeurs correspondantes dans la colonne "domain" par la valeur correspondante dans la colonne "remplacement"
dfMed$domain[idx] <- grp_leven$remplacement[i]
}
## Nombre d'apparitions par année
nb <- dfMed %>%
select(domain, annee)
nb <- nb %>%
group_by(domain, annee) %>%
summarise(n = n())
nb2 <- nb %>%
group_by(annee) %>%
mutate(total = sum(n)) %>%
group_by(domain) %>%
mutate(part = n/total*100) %>%
ungroup()
# Calculer le nombre total de chaque domaine
total_domain <- nb2 %>%
group_by(domain) %>%
summarise(total_domain = sum(n))
# Calculer la part de chaque domaine dans le total de toutes les années
nb3 <- nb2 %>%
left_join(total_domain, by = "domain") %>%
mutate(part_annee = n/sum(n)*100,
part_total = n/total_domain*100) %>%
select(domain, annee, n, part_annee, part_total)
write.xlsx(nb3, "D:/bdd/nombres_par_annee_site.xlsx")
# pivoter l'annee
# Pivoter l'annee pour n'analyse des séquences
nb4 <- nb3 %>%
pivot_wider(names_from = annee, values_from = n, values_fill = 0)
View(nb4)
# pivoter l'annee
# Pivoter l'annee pour n'analyse des séquences
nb4 <- nb3 %>%
select(domain, annee, n)
View(nb4)
View(nb4)
# pivoter l'annee
# Pivoter l'annee pour n'analyse des séquences
nb4 <- nb3 %>%
select(domain, annee, n) %>%
pivot_wider(names_from = annee, values_from = n, values_fill = 0)
View(nb4)
nb4 <- nb4[,1:10]
View(nb4)
## ACP
acp <- dudi.pca(nb4)
## ACP
library(ade4)
row.names(nb4) <- nb4$domain
View(nb4)
nb4 <- nb4[,2:10]
View(nb4)
row.names(nb4) <- nb3$domain
View(total_domain)
View(nb4)
row.names(nb4) <- nb3$domain
# pivoter l'annee
# Pivoter l'annee pour n'analyse des séquences
nb4 <- nb3 %>%
select(domain, annee, n) %>%
pivot_wider(names_from = annee, values_from = n, values_fill = 0)
nb5 <- nb4[,2:10]
row.names(nb5) <- nb4$domain
View(nb5)
## ACP
library(ade4)
acp <- dudi.pca(nb4)
library(FactoMineR)
acp <- PCA(nb4)
acp <- PCA(nb5)
explor::explor(acp)
View(nb5)
acp <- dudi.pca(nb5, scannf = F, nf = Inf)
explor::explor(acp)
acp <- dudi.pca(nb5, scannf = F, nf = Inf)
explor::explor(acp)
acp <- PCA(nb5)
explor::explor(acp)
# calcul de la matrice de distance
md <- dist.dudi(acp)
# calcul de la matrice de distance
md <- dist.dudi(acp)
library(cluster)
md_gower <- daisy(nb5, metric = "gower")
arbre_gower <- hclust(md_gower, method = "ward.D2")
# Une façon plus visuelle de représenter le dendogramme
library(dendextend)
color_branches(arbre, k = 5) %>% ggplot(labels = FALSE)
library(factoextra)
color_branches(arbre_gower, k = 5) %>% ggplot(labels = FALSE)
color_branches(arbre_gower, k = 2) %>% ggplot(labels = FALSE)
color_branches(arbre_gower, k = 3) %>% ggplot(labels = FALSE)
fviz_dend(arbre_gower, k = 5, show_labels = FALSE, rect = TRUE)
explor::explor(acp)
esquisse:::esquisser()
med_top10 <- nb3 %>%
subset(., domain %in% c("retractionwatch","forbetterscience","scienceintegritydigest",
"mythsofvisionscience","wikipedia","sanchak","dovepress",
"raphazlab","publicationethics","content.iospress.com"))
esquisse:::esquisser()
med_top12 <- nb3 %>%
subset(., domain %in% c("retractionwatch","forbetterscience","scienceintegritydigest",
"mythsofvisionscience","wikipedia","sanchak","dovepress",
"raphazlab","publicationethics","content.iospress.com",
"scholarlyoa", "nytimes"))
esquisse:::esquisser()
## select
`%not_in%` <- purrr::negate(`%in%`)
med_autre <- nb3 %>%
subset(., domain %not_in% c("retractionwatch","forbetterscience","scienceintegritydigest",
"mythsofvisionscience","wikipedia","sanchak","dovepress",
"raphazlab","publicationethics","content.iospress.com",
"scholarlyoa", "nytimes"))
View(med_autre)
# Pivoter l'annee pour n'analyse des séquences
nb_autre <- med_autre %>%
select(domain, annee, n) %>%
pivot_wider(names_from = annee, values_from = n, values_fill = 0)
autr_pr_acp <- nb_autre[,2:10]
row.names(autr_pr_acp) <- nb_autre$domain
View(autr_pr_acp)
acp <- dudi.pca(autr_pr_acp, scannf = F, nf = Inf)
explor::explor(acp)
# calcul de la matrice des distances de Gower
library(cluster)
md_gower <- daisy(nb5, metric = "gower")
arbre_gower <- hclust(md_gower, method = "ward.D2")
# Une façon plus visuelle de représenter le dendogramme
library(dendextend)
color_branches(arbre_gower, k = 3) %>% ggplot(labels = FALSE)
acp <- PCA(autr_pr_acp)
acp <- dudi.pca(autr_pr_acp, scannf = F, nf = Inf)
explor::explor(acp)
